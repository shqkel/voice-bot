import streamlit as st
from audiorecorder import audiorecorder
from openai_service import stt, ask_gpt, tts

def main():
    st.set_page_config(
        page_title='ğŸ˜Voice ChatbotğŸ˜',
        page_icon="ğŸ¤",
        layout='wide'
    )
    st.header('ğŸ¤Voice ChatbotğŸ¤')
    st.markdown('---')

    with st.expander('Voice Chatbot í”„ë¡œê·¸ë¨ ì²˜ë¦¬ì ˆì°¨', expanded=False):
        st.write(
            """
            1. ë…¹ìŒí•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸ì„ ë…¹ìŒí•©ë‹ˆë‹¤.
            2. ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ Whisperëª¨ë¸ì„ ì´ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
            3. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¡œ LLMì— ì§ˆì˜í›„ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
            4. LLMì˜ ì‘ë‹µì„ ë‹¤ì‹œ TTSëª¨ë¸ì„ ì‚¬ìš©í•´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì´ë¥¼ ì‚¬ìš©ìì—ê²Œ ë“¤ë ¤ì¤ë‹ˆë‹¤.
            5. ëª¨ë“  ì§ˆë¬¸/ë‹µë³€ì€ ì±„íŒ…í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤.
            """
        )

    system_prompt = 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— 50ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.'
    # session_state ê´€ë¦¬: ì„œë²„ì˜ sessionì— ì‚¬ìš©ìë³€ìˆ˜ë¥¼ ì €ì¥
    if 'messages' not in st.session_state:
        st.session_state['messages'] = [
            {'role': 'system', 'content': system_prompt}    
        ]
    if 'check_reset' not in st.session_state:
        st.session_state['check_reset'] = False


    with st.sidebar:
        model = st.radio(label='GPT ëª¨ë¸', options=['gpt-4.1-mini', 'gpt-5-nano', 'gpt-5.2'], index=0)
        print(f'{model = }')

        if st.button(label='ì´ˆê¸°í™”'):
            st.session_state['messages'] = [
                {'role': 'system', 'content': system_prompt}    
            ]
            st.session_state['check_reset'] = True

    col1, col2 = st.columns(2)
    with col1:
        st.subheader('ë…¹ìŒí•˜ê¸°')
        # 1. ffmpeg ì„¤ì¹˜(os)
        # 2. streamlit-audiorecorder (pip)
        # 3. ì‹¤ì œ ì‚¬ìš©ì‹œ ë¸Œë¼ìš°ì ¸ ë§ˆì´í¬ì‚¬ìš© í—ˆìš©
        audio = audiorecorder()
        # print(audio)
        # print(audio.duration_seconds)

        if (audio.duration_seconds > 0) and (not st.session_state['check_reset']):
            st.audio(audio.export().read()) # ë…¹ìŒëœ ìŒì›íŒŒì¼ì„ í™”ë©´ìƒì— ì¬ìƒ

            # stt ë³€í™˜
            query: str = stt(audio)
            print(f'{query = }')

            # llm ì§ˆì˜
            st.session_state['messages'].append({'role': 'user', 'content': query})
            response: str = ask_gpt(st.session_state['messages'], model)
            print(f'{response = }')
            st.session_state['messages'].append({'role': 'assistant', 'content': response})
            # print(st.session_state['messages'])

            # tts ë³€í™˜
            base64_encoded_audio: str = tts(response) # ì´ì§„ë°ì´í„°ë¥¼ base64ì¸ì½”ë”©í•œ ê²°ê³¼(ë¬¸ìì—´)
            st.html(f'''
            <audio autoplay='true'>
                    <source src='data:audio/mp3;base64,{base64_encoded_audio}'>
            </audio>
            ''')

        else:
            st.session_state['check_reset'] = False # í™”ë©´ ì´ˆê¸°í™”í›„ ë‹¤ì‹œ check_reset Falseì§€ì •

    with col2:
        st.subheader('ì§ˆë¬¸/ë‹µë³€')
        if (audio.duration_seconds > 0) and (not st.session_state['check_reset']):
            for message in st.session_state['messages']:
                role = message['role']
                content = message['content']

                if role == 'system':
                    continue

                # ì—­í• ë³„ ì±„íŒ…ë©”ì„¸ì§€ ì¶œë ¥
                with st.chat_message(role):
                    st.markdown(content)



if __name__ == '__main__':
    main()
